# -*- coding: utf-8 -*-
"""Telco_Customer_Churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BPz4nm8gHwhYfJJZ_vM7HPuyNqT1c3NK
"""

# STEP-1 : IMPORT REQUIRED LIBRARIES

import pandas as pd
import matplotlib.pyplot  as plt
from sklearn.model_selection import train_test_split
import torch.nn as nn
import torch.optim as optim
import torch
from torch.utils.data import Dataset , DataLoader
from sklearn.preprocessing import StandardScaler

# STEP-2 : IMPORT DATAFRAME

df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')
df.head()

# STEP-3 : DROP ID COLUMN (IRRELEVANT TO THE NN)

df.drop('customerID' , axis = 1, inplace = True)
df.head()

df.dtypes

# STEP-4 : FIX THE DATA IN THE TABLE TO MAKE IT APPROPRIATE FOR A NN

df['Churn']= df['Churn'].map({'Yes': 1, 'No': 0})

columns = ['gender', 'Partner', 'Dependents', 'PhoneService',
           'PaperlessBilling']
for column in columns:
  df[column] = df[column].map({'Yes': 1, 'No': 0,
                               'Male': 1, 'Female': 0})
df.head()

df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")
df["TotalCharges"].fillna(df["TotalCharges"].median(), inplace=True)

y = df["Churn"]
X = df.drop("Churn", axis=1)

X = pd.get_dummies(X, drop_first=True)
X = X.astype(int)

X.head()

y.head()

# STEP-5 : TRAIN-TEST SPLIT

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17)

# STEP-6: SCALING & TENSOR CONVERSION OF THE DATA

scaler = StandardScaler()

X_train = scaler.fit_transform(X_train.values)
X_test  = scaler.transform(X_test.values)

X_train = torch.tensor(X_train, dtype=torch.float32)
X_test  = torch.tensor(X_test, dtype=torch.float32)

y_train = torch.tensor(y_train.values, dtype=torch.float32)
y_test  = torch.tensor(y_test.values, dtype=torch.float32)

# STEP-7 : CUSTOM DATASET CLASS FORMATION

class ChurnDataset(Dataset):
    def __init__(self, X, y):
        self.X = X
        self.y = y

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

train_data = ChurnDataset(X_train, y_train)
test_data  = ChurnDataset(X_test, y_test)

train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
test_loader  = DataLoader(test_data, batch_size=32, shuffle=False)

# STEP-8 : NEURAL NETWORK SETUP

class ChurnNN(nn.Module):

  def __init__(self , num_features):
    super().__init__()
    self.Network = nn.Sequential(
        nn.Linear(num_features , 32),
        nn.ReLU(),
        nn.Dropout(0.3),
        nn.Linear(32 , 16),
        nn.ReLU(),
        nn.Linear(16 , 1)
    )

  def forward(self,x):
    return self.Network(x)

model = ChurnNN(X_train.shape[1])

# STEP-9 : PARAMETERS

loss = nn.BCEWithLogitsLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)
epochs = 20

# STEP-10 : TRAINING LOOP

for epoch in range (epochs):

  epoch_loss = 0.0

  for batch_features,batch_labels in train_loader:

    y_pred = model.forward(batch_features).squeeze()
    batch_loss = loss(y_pred, batch_labels)

    optimizer.zero_grad()
    batch_loss.backward()
    optimizer.step()

    epoch_loss += batch_loss.item()

  avg_epoch_loss = epoch_loss / len(train_loader)
  print('epoch - ', epoch+1 , 'loss - ', avg_epoch_loss)

model.eval()

total = 0
correct = 0

with torch.no_grad():
    for batch_features, batch_labels in test_loader:

        # forward pass
        out = model(batch_features).squeeze()

        # sigmoid + threshold
        probs = torch.sigmoid(out)
        preds = (probs >= 0.5).float()

        total += batch_labels.size(0)
        correct += (preds == batch_labels).sum().item()

print("Accuracy -", correct / total)

